{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesharmavikash/AgentGPT/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971393bb-224b-40c0-a680-e74496d8cd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Fooocus-MRE'...\n",
            "remote: Enumerating objects: 7729, done.\u001b[K\n",
            "remote: Total 7729 (delta 0), reused 0 (delta 0), pack-reused 7729 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7729/7729), 33.52 MiB | 24.64 MiB/s, done.\n",
            "Resolving deltas: 100% (4576/4576), done.\n",
            "/content/Fooocus-MRE\n",
            "Collecting pygit2==1.12.2\n",
            "  Downloading pygit2-1.12.2.tar.gz (738 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.5/738.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from pygit2==1.12.2) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.9.1->pygit2==1.12.2) (2.23)\n",
            "Building wheels for collected packages: pygit2\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pygit2 \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pygit2 (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pygit2\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pygit2\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygit2)\u001b[0m\u001b[31m\n",
            "\u001b[0mAlready up-to-date\n",
            "Update succeeded.\n",
            "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Fooocus version: 2.0.78.5 MRE\n",
            "Inference Engine cloned.\n",
            "Inference Engine checkout finished.\n",
            "Installing xformers\n",
            "Couldn't install xformers.\n",
            "Command: \"/usr/bin/python3\" -m pip install -U -I --no-deps xformers==0.0.21 --prefer-binary\n",
            "Error code: 1\n",
            "stdout: Collecting xformers==0.0.21\n",
            "  Downloading xformers-0.0.21.tar.gz (22.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.3/22.3 MB 116.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n",
            "\n",
            "stderr:   error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py egg_info did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> See above for output.\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "× Encountered error while generating package metadata.\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n",
            "\n",
            "CMD Failed xformers: install -U -I --no-deps xformers==0.0.21\n",
            "Installing requirements\n",
            "Couldn't install requirements.\n",
            "Command: \"/usr/bin/python3\" -m pip install -r \"requirements_versions.txt\" --prefer-binary\n",
            "Error code: 1\n",
            "stdout: Collecting torchsde==0.2.5 (from -r requirements_versions.txt (line 1))\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl.metadata (748 bytes)\n",
            "\n",
            "stderr: WARNING: Ignoring version 0.2.5 of torchsde since it has invalid metadata:\n",
            "Requested torchsde==0.2.5 from https://files.pythonhosted.org/packages/73/8d/efd3e7b31ea854d0bd6886aa3cf44914adce113a6d460850af41ac1dd4dd/torchsde-0.2.5-py3-none-any.whl (from -r requirements_versions.txt (line 1)) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
            "           ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\n",
            "ERROR: Could not find a version that satisfies the requirement torchsde==0.2.5 (from versions: 0.2.5, 0.2.6)\n",
            "ERROR: No matching distribution found for torchsde==0.2.5\n",
            "\n",
            "CMD Failed requirements: install -r \"requirements_versions.txt\"\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors\" to /content/Fooocus-MRE/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:07<00:00, 102MB/s] \n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors\" to /content/Fooocus-MRE/models/checkpoints/sd_xl_refiner_1.0_0.9vae.safetensors\n",
            "\n",
            "100% 5.66G/5.66G [00:57<00:00, 106MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus-MRE/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:02<00:00, 19.2MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/control-lora/resolve/main/revision/clip_vision_g.safetensors\" to /content/Fooocus-MRE/models/clip_vision/clip_vision_g.safetensors\n",
            "\n",
            "100% 3.44G/3.44G [00:43<00:00, 84.1MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank128/control-lora-canny-rank128.safetensors\" to /content/Fooocus-MRE/models/controlnet/control-lora-canny-rank128.safetensors\n",
            "\n",
            "100% 377M/377M [00:02<00:00, 145MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors\" to /content/Fooocus-MRE/models/controlnet/control-lora-canny-rank256.safetensors\n",
            "\n",
            "100% 739M/739M [00:09<00:00, 79.2MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank128/control-lora-depth-rank128.safetensors\" to /content/Fooocus-MRE/models/controlnet/control-lora-depth-rank128.safetensors\n",
            "\n",
            "100% 377M/377M [00:05<00:00, 71.6MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors\" to /content/Fooocus-MRE/models/controlnet/control-lora-depth-rank256.safetensors\n",
            "\n",
            "100% 739M/739M [00:11<00:00, 64.6MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus-MRE/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 1.76MB/s]\n",
            "Downloading: \"https://github.com/madebyollin/taesd/raw/main/taesd_decoder.pth\" to /content/Fooocus-MRE/models/vae_approx/taesd_decoder.pth\n",
            "\n",
            "100% 4.69M/4.69M [00:00<00:00, 106MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_upscaler_s409985e5.bin\" to /content/Fooocus-MRE/models/upscale_models/fooocus_upscaler_s409985e5.bin\n",
            "\n",
            "100% 32.1M/32.1M [00:00<00:00, 46.1MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus-MRE/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:03<00:00, 97.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/MoonRide303/Fooocus-MRE.git\n",
        "%cd Fooocus-MRE\n",
        "!cp settings-no-refiner.json settings.json\n",
        "!pip install pip==23.3.1 # Downgrade pip to resolve torchsde metadata issue\n",
        "!python entry_with_update.py --share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}